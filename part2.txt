	\subsection{ب: مسئلۀ مسکن}
\begin{enumerate}
	
	\item بارگذاری داده ها
	
	در این مرحله، داده‌ها از فایل \lr{CSV} خوانده می‌شوند. ما با استفاده از کتابخانه \lr{pandas} که برای کار با داده‌های جدولی بسیار مناسب است، داده‌ها را به صورت یک \lr{DataFrame} وارد برنامه می‌کنیم. این ساختار امکان انجام پردازش‌های بعدی مانند پاکسازی و انتخاب ویژگی را بسیار ساده می‌کند. هدف اصلی این مرحله بارگذاری کامل و صحیح داده‌ها بدون خطا است تا آماده تحلیل و مدل‌سازی شوند.
	
	\begin{latin}
		\begin{lstlisting}
			import pandas as pd
			data = pd.read_csv('path_to_boston_data.csv')
		\end{lstlisting}
	\end{latin}
	
	\item پیش  پردازش
	
	در این بخش، ابتدا با استفاده از متد \lr{dropna()}، ردیف‌هایی که شامل مقادیر گم‌شده (\lr{NaN}) هستند حذف می‌شوند تا کیفیت داده‌ها تضمین شود. سپس داده‌ها به دو بخش ویژگی‌ها و متغیر هدف تقسیم می‌شوند. ویژگی‌ها (\lr{X}) شامل تمام ستون‌ها به جز \lr{CRIM} هستند که نشان‌دهنده نرخ جرم در منطقه است. متغیر هدف (\lr{y}) نیز همان ستون \lr{CRIM} می‌باشد. این جداسازی برای آماده‌سازی داده جهت آموزش مدل بسیار ضروری است.
	
	\begin{latin}
		\begin{lstlisting}
			data = data.dropna()
			X = data.drop('CRIM', axis=1)
			y = data['CRIM']
		\end{lstlisting}
	\end{latin}
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{dib5.jpg} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{برش داده ها}
	\end{figure}
	
	
	
	\item انتخاب ویژگی
	
	در این مرحله، هدف اصلی کاهش ابعاد داده و انتخاب ویژگی‌های مهم برای مدل‌سازی است. ابتدا با استفاده از تحلیل همبستگی (\lr{Correlation})، ارتباط بین ویژگی‌ها و متغیر هدف بررسی می‌شود تا ویژگی‌هایی که تاثیر بیشتری دارند شناسایی شوند. سپس از مدل \lr{Decision Tree} برای ارزیابی اهمیت هر ویژگی استفاده می‌کنیم. این دو روش مکمل یکدیگرند و ترکیب نتایج آن‌ها باعث انتخاب مجموعه‌ای از ویژگی‌های مرتبط و مفید برای مدل می‌شود. در نهایت ویژگی‌های منتخب در \lr{final\_selected\_features} ذخیره می‌شوند و داده‌ها به آن‌ها محدود می‌شوند.
	
	\begin{latin}
		\begin{lstlisting}
			import numpy as np
			from sklearn.tree import DecisionTreeRegressor
			
			corr = X.corrwith(y).abs()
			important_corr_features = corr[corr > 0.3].index.tolist()
			
			tree = DecisionTreeRegressor(random_state=42)
			tree.fit(X, y)
			importances = pd.Series(tree.feature_importances_, index=X.columns)
			important_tree_features = importances[importances > 0.05].index.tolist()
			
			final_selected_features = list(set(important_corr_features).intersection(important_tree_features))
			X = X[final_selected_features]
		\end{lstlisting}
	\end{latin}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{fs1.png} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{انتخاب ویژگی با مدل اول}
	\end{figure}
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{fs2.png} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{انتخاب ویژگی با مدل دوم}
	\end{figure}
	
	
	
	\item تقسیم و استاندارد سازی
	
	در این مرحله، داده‌ها به دو مجموعه تقسیم می‌شوند: مجموعه آموزش و تنظیم مدل (۸۰٪) و مجموعه آزمایش نهایی (۲۰٪). این کار با هدف حفظ ارزیابی نهایی مدل روی داده‌های دیده نشده انجام می‌شود. سپس برای اطمینان از اینکه همه ویژگی‌ها به طور مساوی در محاسبات فاصله نقش دارند، داده‌ها استاندارد می‌شوند. مهم است که \lr{StandardScaler} فقط روی داده‌های آموزش آموزش داده شود تا از \lr{data leakage} جلوگیری شود و سپس همین scaler برای مقیاس‌دهی داده‌های آزمایش استفاده شود.
	
	\begin{latin}
		\begin{lstlisting}
			from sklearn.model_selection import train_test_split
			from sklearn.preprocessing import StandardScaler
			
			X_train_full, X_test, y_train_full, y_test = train_test_split(
			X, y, test_size=0.2, random_state=42, stratify=y
			)
			
			scaler = StandardScaler()
			X_train_full_scaled = scaler.fit_transform(X_train_full)
			X_test_scaled = scaler.transform(X_test)
		\end{lstlisting}
	\end{latin}
	
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{rate.png} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{\lr{Exploratory Data Analysis on Crime Rate}}
	\end{figure}		
	
	
	\item میزان بهینه \lr{K}
	
	در این بخش، هدف تعیین بهترین مقدار \lr{k} برای الگوریتم \lr{KNN} است. سه روش مختلف برای انتخاب \lr{k} مقایسه می‌شوند: \lr{Holdout Validation}، \lr{Cross-Validation} و معیار \lr{Multiclass AUC}. هر روش مزایا و محدودیت‌های خود را دارد. ابتدا داده آموزش به بخش آموزش و اعتبارسنجی تقسیم می‌شود، سپس هر سه روش اجرا و نتایج مقایسه می‌شوند. در نهایت، مقدار \lr{k} به گونه‌ای انتخاب می‌شود که تعادل بهتری بین دقت و تعمیم مدل برقرار کند.
	
	\begin{latin}
		\begin{lstlisting}
			from sklearn.neighbors import KNeighborsClassifier
			from sklearn.metrics import accuracy_score, roc_auc_score
			from sklearn.model_selection import cross_val_score
			from sklearn.preprocessing import LabelBinarizer
			import matplotlib.pyplot as plt
			import numpy as np
			
			k_range = range(1, 31)
			
			# Holdout Validation
			X_train, X_val, y_train, y_val = train_test_split(
			X_train_full_scaled, y_train_full, test_size=0.25, random_state=42, stratify=y_train_full
			)
			holdout_scores = []
			for k in k_range:
			knn = KNeighborsClassifier(n_neighbors=k)
			knn.fit(X_train, y_train)
			holdout_scores.append(accuracy_score(y_val, knn.predict(X_val)))
			
			# Cross-Validation
			cv_scores = []
			for k in k_range:
			knn = KNeighborsClassifier(n_neighbors=k)
			scores = cross_val_score(knn, X_train_full_scaled, y_train_full, cv=10, scoring='accuracy')
			cv_scores.append(scores.mean())
			
			# Multiclass AUC
			lb = LabelBinarizer()
			y_val_binarized = lb.fit_transform(y_val)
			roc_auc_scores = []
			for k in k_range:
			knn = KNeighborsClassifier(n_neighbors=k)
			knn.fit(X_train, y_train)
			y_pred_proba = knn.predict_proba(X_val)
			roc_auc_scores.append(roc_auc_score(y_val_binarized, y_pred_proba, multi_class='ovr', average='macro'))
			
			optimal_k = 6  # فرض شده بر اساس نتایج
		\end{lstlisting}
	\end{latin}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{k.png} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{میزان بهینه \lr{K}}
	\end{figure}
	
	
	\item ارزیابی و نتایج
	
	در این مرحله، مدل \lr{KNN} با مقدار بهینه \lr{k} که در مرحله قبل انتخاب شد، روی کل داده آموزش آموزش داده می‌شود تا از همه اطلاعات موجود برای ساخت مدل استفاده شود. سپس مدل روی داده آزمایش دیده نشده تست می‌شود تا دقت واقعی آن سنجیده شود. نتایج شامل دقت نهایی، گزارش طبقه‌بندی و ماتریس ابهام برای بررسی عملکرد دقیق‌تر ارائه می‌شوند.
	
	در بخش نهایی، خلاصه‌ای از پارامترهای کلیدی مدل و نتایج مهم ارائه می‌شود تا یک دید کلی از عملکرد مدل به دست آید. سپس تفسیر مفصل نتایج و دلایل اتخاذ هر تصمیم به صورت متنی آمده است تا طیف گسترده ای از خوانندگان نیز به خوبی مفهوم را درک کند. در نهایت، نکات عملی و کاربردی که از مدل استخراج شده است، بیان می‌شود تا ارزش مدل در پروژه‌های واقعی مشخص شود.
	
	\begin{latin}
		\begin{lstlisting}
			from sklearn.metrics import classification_report, confusion_matrix
			import seaborn as sns
			
			final_model = KNeighborsClassifier(n_neighbors=optimal_k)
			final_model.fit(X_train_full_scaled, y_train_full)
			y_pred = final_model.predict(X_test_scaled)
			
			final_accuracy = accuracy_score(y_test, y_pred)
			
			print(f"Final Accuracy: {final_accuracy:.2%}")
			print(classification_report(y_test, y_pred, target_names=['Low', 'Moderate', 'High']))
			
			labels_order = sorted(y.unique())
			cm = confusion_matrix(y_test, y_pred, labels=labels_order)
			plt.figure(figsize=(8, 6))
			sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
			xticklabels=labels_order, yticklabels=labels_order)
			plt.xlabel('Predicted Label')
			plt.ylabel('True Label')
			plt.title(f'Confusion Matrix (k={optimal_k})')
			plt.show()
			
			
			
			print(f"Number of Features Selected: {len(final_selected_features)}")
			print(f"Features Used: {final_selected_features}")
			print(f"Optimal k: {optimal_k}")
			print(f"Final Model Accuracy: {final_accuracy:.2%}")
		\end{lstlisting}
	\end{latin}
	
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.45\textwidth]{mat.png} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{\lr{Confusion Matrix}}
	\end{figure}
	
	
	
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.55\textwidth]{dib6.jpg} % فرض کنید این تصویر را ذخیره کرده‌اید
		\caption{نتایج}
	\end{figure}
	
	
\end{enumerate}
